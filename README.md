# Практика JUSTAI

## First task

* Первая задача связана с обновлением ответов моделей Gigachat и YandexGPT на данном тестсете. 
* С помощью модели-оракула ответы проверяются по бинарной шкале Истина / Ложь. Если ответ ложный, то даётся комментарий. Промпт можно посмотреть в файле [help_funcs.py](first_task/help_funcs.py). Кол-во правильных ответов сравнивается с предыдущими версиями моделей.
* По итогам задания был написан отчёт, отражающий сильные и слабые стороны моделей. 

## Synthetic testset

* С помощью фреймворка ragas и набора данных, на которых обучена вопросно-ответная система по FAQ по продуктам JustAI, был сгенерирован искусственный датасет с различными типами вопросов.
* Датасет составляет 34 вопроса с ответом и истинным контекстом, а также типом вопроса.
* С помощью интерфейса к модели JustGPT, развёрнутого на swagger, были извлечены найденные контексты, которые используются моделью для ответа на вопрос, и ответы.
* Итоговый датасет имеет такие столбцы: `['question', 'contexts', 'answer', 'ground_truths']`. 
* Впоследствии, были добавлены также метрики `Faithfulness, Answer Relevancy, Context Precision`. С остальными метриками из фреймворка возникла проблема, которая не позволила их использовать. (**to be done**)  
* Добавлена визуализации метрик. См. файл [metrics_visualization.ipynb](synthetic_testset/metrics_visualization.ipynb).

## Original testset
* На основе данных вопросов и ответов к ним, которые мы считаем за ground_truths, с помощью интерфейса к JustGPT был составлен датасет в таком же формате, как и описанный до этого.
* Были использованы такие же метрики и добавлена такая же визуализация. См файл [metrics_visualization.ipynb](original_testset/metrics_visualization.ipynb).